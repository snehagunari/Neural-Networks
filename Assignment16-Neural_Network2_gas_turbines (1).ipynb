{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "548a2ebf",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "Predicting turbine energy yield (TEY) using ambient variables as features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31045e91",
   "metadata": {},
   "source": [
    "# Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e5c3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c23ec38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('gas_turbines.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca7deb7",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92385baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32144b6",
   "metadata": {},
   "source": [
    "### Descriptive Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35acdee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6058f64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248c7672",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b89bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82ba97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb37d5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()[\"TEY\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813d2230",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = df.describe(include=[\"int64\",\"float64\"]).columns\n",
    "numerical_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a981fd23",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08e05fc",
   "metadata": {},
   "source": [
    "### Univariate plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1382b481",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "numerical_features=[feature for feature in df.columns if df[feature].dtypes != 'O']\n",
    "for feat in numerical_features:\n",
    "    skew = df[feat].skew()\n",
    "    sns.distplot(df[feat], kde= False, label='Skew = %.3f' %(skew), bins=30)\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bed9251",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.histplot(data=df,x=\"TEY\",color=\"red\",kde=True)\n",
    "plt.axvline(x=df[\"TEY\"].mean(),ymax=0.55,color=\"green\",linestyle='--',label=\"Mean\")\n",
    "plt.axvline(x=df[\"TEY\"].median(),ymax=0.56,color=\"purple\",linestyle='--',label=\"Median\")\n",
    "plt.legend()\n",
    "plt.title(\"Histogram of the Target Column\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03527152",
   "metadata": {},
   "source": [
    "###### Unsurprisingly, Mostly none of the features are on the same scale as we already saw in the previous section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff0ee81",
   "metadata": {},
   "source": [
    "### Multivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffea1ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df,\n",
    "                 markers=\"+\",\n",
    "                 kind='reg',\n",
    "                 diag_kind=\"auto\",\n",
    "                 plot_kws={'line_kws':{'color':'#aec6cf'},\n",
    "                           'scatter_kws': {'alpha': 0.5,\n",
    "                                           'color': '#82ad32'}},\n",
    "               \n",
    "                 diag_kws= {'color': '#82ad32'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b0e23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('TEY', axis=1)\n",
    "y = df[[\"TEY\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8a928d",
   "metadata": {},
   "source": [
    "# Feature Selection Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00ab749",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import set_printoptions\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1835a699",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = SelectKBest(score_func = mutual_info_regression, k ='all')\n",
    "fit = test.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac45ad24",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = fit.scores_\n",
    "features = fit.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631b7ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df = pd.DataFrame(list(zip(scores, x.columns)), columns = ['Score', 'Feature'])\n",
    "score_df.sort_values(by =\"Score\", ascending = False, inplace = True)\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71da6e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize = (20, 6))\n",
    "plt.bar([i for i in range(len(scores))], scores)\n",
    "axes.set_xticks([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "axes.set_xticklabels(x.columns.values)\n",
    "plt.xticks(rotation = 90, size = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec55378d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "sns.barplot(x ='Feature', y =\"Score\", data = score_df, order = score_df.sort_values('Score').Feature)\n",
    "plt.xlabel(\"Features\", size=15)\n",
    "plt.ylabel(\"Scores\", size=15)\n",
    "plt.yticks(rotation = 0, fontsize = 14)\n",
    "plt.xticks(rotation = 90, fontsize = 16)\n",
    "plt.title(\"Feature Score w.r.t the Sales\", size=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813239cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df.sort_values('Score', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2621d2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = df[['CDP', 'GTEP','TIT', 'TAT', 'AFDP', 'CO', 'AT',\"TEY\"]]\n",
    "model_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09106a58",
   "metadata": {},
   "source": [
    "### 5.1. Data Pre-Processing\n",
    "##### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bd7eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_feature=[feature for feature in model_data.columns if model_data[feature].dtype !='O']\n",
    "print('Continuous Feature Count {}'.format(len(continuous_feature)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644c08bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_standard_scaled = model_data.copy()\n",
    "features = df_standard_scaled[continuous_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04c55b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df_standard_scaled[continuous_feature] = scaler.fit_transform(features.values)\n",
    "df_standard_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4c5103",
   "metadata": {},
   "source": [
    "### Test Train Split With Imbalanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0db979",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_standard_scaled.drop('TEY',axis=1)\n",
    "y = df_standard_scaled[['TEY']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5912e9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c777027f",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b81133",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning: Optimal Learning rate ,Number of Layers and Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae84160f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    for i in range(hp.Int('num_layers', 2, 20)):\n",
    "        model.add(layers.Dense(units=hp.Int('units_' + str(i), min_value=32, max_value=100, step=32), activation = 'relu'))\n",
    "    model.add(layers.Dense(1, activation='linear'))\n",
    "    model.compile(optimizer = keras.optimizers.Adam(hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n",
    "                  loss ='mean_absolute_error', metrics =['mean_absolute_error'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15604972",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kerastuner\n",
    "!pip install --upgrade pip\n",
    "\n",
    "\n",
    "from kerastuner.tuners import RandomSearch\n",
    "tuner = RandomSearch(build_model, objective ='val_mean_absolute_error', max_trials = 5, executions_per_trial = 3,\n",
    "                     directory ='project', project_name ='Gas Turbine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab794ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1624035d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tuner.search(x_train, y_train, epochs = 100, validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de278de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15dc14f",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning: Optimal Batch_size, Number of Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bce4e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "def create_model():\n",
    "    model1 = Sequential()\n",
    "    model1.add(Dense(32, input_dim = 7, activation ='relu'))\n",
    "    model1.add(Dense(64, activation ='relu'))\n",
    "    model1.add(Dense(96, activation =\"relu\"))\n",
    "    model1.add(Dense(32, activation =\"relu\"))\n",
    "    model1.add(Dense(64, activation =\"relu\"))\n",
    "    model1.add(Dense(32, activation =\"relu\"))\n",
    "    model1.add(Dense(96, activation =\"relu\"))\n",
    "    model1.add(Dense(96, activation =\"relu\"))\n",
    "    model1.add(Dense(32, activation =\"relu\"))\n",
    "    model1.add(Dense(64, activation =\"relu\"))\n",
    "    model1.add(Dense(64, activation =\"relu\"))\n",
    "    model1.add(Dense(units = 1, activation =\"linear\"))\n",
    "    adam = Adam(learning_rate=0.001)\n",
    "    model1.compile(loss ='mean_absolute_error', optimizer = adam, metrics = [\"mean_absolute_error\"])\n",
    "    return model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528f2c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = KerasRegressor(build_fn = create_model, verbose = 0)\n",
    "batch_size = [10, 20, 40, 50]\n",
    "epochs = [10, 50, 100, 200]\n",
    "param_grid = dict(batch_size = batch_size, epochs = epochs)\n",
    "grid = GridSearchCV(estimator = model1, param_grid = param_grid, cv = KFold(), verbose = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab1f09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result = grid.fit(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16632124",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best {}, using {}'.format(grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_[\"mean_test_score\"]\n",
    "stds = grid_result.cv_results_[\"std_test_score\"]\n",
    "params = grid_result.cv_results_[\"params\"]\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"{},{} with {}\".format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ed4771",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning: Optimal Droupout rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006813ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "\n",
    "def create_model(dropout_rate):\n",
    "    model2 = Sequential()\n",
    "    model2.add(Dense(32, input_dim = 7, activation ='relu'))\n",
    "    model2.add(Dense(64, activation ='relu'))\n",
    "    model2.add(Dense(96, activation =\"relu\"))\n",
    "    model2.add(Dense(32, activation =\"relu\"))\n",
    "    model2.add(Dense(64, activation =\"relu\"))\n",
    "    model2.add(Dense(32, activation =\"relu\"))\n",
    "    model2.add(Dense(96, activation =\"relu\"))\n",
    "    model2.add(Dense(96, activation =\"relu\"))\n",
    "    model2.add(Dense(32, activation =\"relu\"))\n",
    "    model2.add(Dense(64, activation =\"relu\"))\n",
    "    model2.add(Dense(64, activation =\"relu\"))\n",
    "    model2.add(Dense(units = 1, activation =\"linear\"))\n",
    "    adam = Adam(learning_rate = 0.001)\n",
    "    model2.compile(loss ='mean_absolute_error', optimizer = adam, metrics = [\"mean_absolute_error\"])\n",
    "    return model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea9ecd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = KerasRegressor(build_fn = create_model, batch_size = 40, epochs = 200, verbose = 0)\n",
    "dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "param_grid = dict(dropout_rate = dropout_rate)\n",
    "grid2 = GridSearchCV(estimator = model2, param_grid = param_grid, cv = KFold(), verbose = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a562caaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result2 = grid2.fit(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ae8961",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best {}, using {}'.format(grid_result2.best_score_, grid_result2.best_params_))\n",
    "means = grid_result2.cv_results_[\"mean_test_score\"]\n",
    "stds = grid_result2.cv_results_[\"std_test_score\"]\n",
    "params = grid_result2.cv_results_[\"params\"]\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"{},{} with {}\".format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df66caa",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning: Optimal Activation Function and Kernel Initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7db075",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(activation_function, init):\n",
    "    model3 = Sequential()\n",
    "    model3.add(Dense(32, input_dim = 7, activation ='relu'))\n",
    "    model3.add(Dropout(0.3))\n",
    "    model3.add(Dense(64, activation ='relu'))\n",
    "    model3.add(Dropout(0.3))\n",
    "    model3.add(Dense(96, activation =\"relu\"))\n",
    "    model3.add(Dropout(0.3))\n",
    "    model3.add(Dense(32, activation =\"relu\"))\n",
    "    model3.add(Dropout(0.3))\n",
    "    model3.add(Dense(64, activation =\"relu\"))\n",
    "    model3.add(Dropout(0.3))\n",
    "    model3.add(Dense(32, activation =\"relu\"))\n",
    "    model3.add(Dropout(0.3))\n",
    "    model3.add(Dense(96, activation =\"relu\"))\n",
    "    model3.add(Dropout(0.3))\n",
    "    model3.add(Dense(96, activation =\"relu\"))\n",
    "    model3.add(Dropout(0.3))\n",
    "    model3.add(Dense(32, activation =\"relu\"))\n",
    "    model3.add(Dropout(0.3))\n",
    "    model3.add(Dense(64, activation =\"relu\"))\n",
    "    model3.add(Dropout(0.3))\n",
    "    model3.add(Dense(64, activation =\"relu\"))\n",
    "    model3.add(Dropout(0.3))\n",
    "    model3.add(Dense(units = 1, activation =\"linear\"))\n",
    "    \n",
    "    adam=Adam(learning_rate = 0.001)\n",
    "    model3.compile(loss ='mean_absolute_error', optimizer = adam, metrics = [\"mean_absolute_error\"])\n",
    "    return model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe51ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = KerasRegressor(build_fn = create_model, batch_size = 40, epochs = 200, verbose = 0)\n",
    "activation_function = ['softmax','tanh','relu']\n",
    "init = ['normal','uniform','zero']\n",
    "param_grid = dict(activation_function = activation_function, init = init)\n",
    "grid3 = GridSearchCV(estimator = model3, param_grid = param_grid, cv = KFold(), verbose = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b0dc48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_result3 = grid3.fit(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3812f5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best {}, using {}'.format(grid_result3.best_score_, grid_result3.best_params_))\n",
    "means = grid_result3.cv_results_[\"mean_test_score\"]\n",
    "stds = grid_result3.cv_results_[\"std_test_score\"]\n",
    "params = grid_result3.cv_results_[\"params\"]\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"{},{} with {}\".format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1044a048",
   "metadata": {},
   "source": [
    "# Model Building Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf18d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca80c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model_data.drop('TEY', axis = 1)\n",
    "y = model_data[[\"TEY\"]]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state = 42)\n",
    "\n",
    "scaler_train = StandardScaler()\n",
    "scaler_test = StandardScaler()\n",
    "\n",
    "x_train_scaled = scaler_train.fit_transform(x_train) \n",
    "x_test_scaled  = scaler_test.fit_transform(x_test) \n",
    "\n",
    "print(x_train_scaled.shape)\n",
    "print(x_test_scaled.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d215b53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units = 50 , activation = 'relu', kernel_initializer = 'normal', input_dim = 7))\n",
    "model.add(Dense(units = 20 , activation = 'tanh', kernel_initializer = 'normal')) \n",
    "model.add(Dense(units = 1  , kernel_initializer = 'normal')) \n",
    "\n",
    "model.compile(optimizer = \"adam\", loss =\"mse\", metrics = [\"mae\", \"mse\"])\n",
    "history = model.fit(x_train_scaled, y_train , batch_size = 50, validation_split = 0.3, epochs = 100,  verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69239aee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def toFindBestParams(x_train_scaled, y_train, x_test_scaled, y_test):\n",
    "    batch_size_list = [5 , 10 , 15 , 20]\n",
    "    epoch_list      = [5 , 10 , 50 , 100]\n",
    "    bestParamTable = pd.DataFrame()\n",
    "    \n",
    "    for batch_trial in batch_size_list:\n",
    "        for epochs_trial in epoch_list:\n",
    "            model = Sequential()\n",
    "            model.add(Dense(units = 50, input_dim = x_train_scaled.shape[1], kernel_initializer ='normal', activation ='relu'))\n",
    "            model.add(Dense(units = 20, kernel_initializer ='normal', activation ='tanh'))\n",
    "            model.add(Dense(1, kernel_initializer ='normal'))\n",
    "            model.compile(optimizer ='adam', loss = 'mean_squared_error')\n",
    "            model.fit(x_train_scaled, y_train , batch_size = batch_trial, epochs = epochs_trial,  verbose = 0)\n",
    "            MAPE = np.mean(100 * (np.abs(y_test - model.predict(x_test_scaled))/ y_test))  \n",
    "            bestParamTable = bestParamTable.append(pd.DataFrame(data = [[batch_trial, epochs_trial, 100 - MAPE]],\n",
    "                                                        columns = ['batchsize','epochs','Accuracy'] ))\n",
    "            print('batch_size:', batch_trial,'-', 'epochs:',epochs_trial, 'Accuracy:',100-MAPE)\n",
    "    return bestParamTable\n",
    "\n",
    "finalParamTable = toFindBestParams(x_train_scaled, y_train, x_test_scaled, y_test)\n",
    "finalParamTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be793ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalParamTable = finalParamTable.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7000a34",
   "metadata": {},
   "source": [
    "#### Training Model - using best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b697f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer ='adam', loss = 'mean_squared_error')\n",
    "model.fit(x_train_scaled, y_train, batch_size = 20 , epochs = 100, verbose = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c9c548",
   "metadata": {},
   "source": [
    "### Predicting values from Model using same dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908a7975",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_test = model.predict(x_test_scaled) \n",
    "predictions_df = pd.DataFrame(x_test)\n",
    "predictions_df['Actual'] = y_test\n",
    "predictions_df['Predicted'] = y_predict_test\n",
    "print(predictions_df.shape)\n",
    "predictions_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bc9e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df.drop(['CDP','GTEP','TIT','TAT','AFDP','CO','AT'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f114b0",
   "metadata": {},
   "source": [
    "### Calculating Absolute Percent Error and Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fef49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the absolute percent error\n",
    "APE=100*(abs(predictions_df['Actual'] - predictions_df['Predicted'])/predictions_df['Actual'])\n",
    "print('The Accuracy for Test Data -- ANN model = ', 100-np.mean(APE))\n",
    "\n",
    "# adding absolute percent error to table\n",
    "predictions_df['APE %'] = APE\n",
    "predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3808c96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df['Error'] = (predictions_df['Actual'] - predictions_df['Predicted'])/(predictions_df['Actual'])\n",
    "predictions_df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0eff59",
   "metadata": {},
   "source": [
    "### Visualizing the Relationship between the Actual and Predicted ValuesModel Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed55a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,8))\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Predicted values\")\n",
    "plt.title(\"The Scatterplot of Relationship between Actual Values and Predictions\")\n",
    "plt.scatter(predictions_df['Actual'], predictions_df['Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d28796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will evaluate our model performance by calculating the residual sum of squares and the explained variance score\n",
    "from sklearn import metrics\n",
    "print(\"MAE:\", metrics.mean_absolute_error(y_test, y_predict_test))\n",
    "print (\"MSE:\", metrics.mean_squared_error(y_test, y_predict_test))\n",
    "print(\"RMSE:\", np.sqrt(metrics.mean_squared_error(y_test, y_predict_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918a4106",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "y_predict_test = model.predict(x_test_scaled)\n",
    "y_predict_train = model.predict(x_train_scaled) \n",
    "print('R2_score (train): ', r2_score(y_train, y_predict_train))\n",
    "print('R2_score (test): ', r2_score(y_test, y_predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3cba98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation of  the explained variance score (R^2)\n",
    "print('This shows our model predict % {} of the target correctly'.format(np.round(metrics.explained_variance_score(y_test,y_predict_test)*100,2))) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc39526c",
   "metadata": {},
   "source": [
    "### Residual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d09cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "sns.distplot(y_test - y_predict_test, bins = 50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d309061b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as smf\n",
    "smf.qqplot(predictions_df['Error'], line = 'q')\n",
    "plt.title('Normal Q-Q plot of residuals')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
